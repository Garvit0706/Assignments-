{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d32caf-0eb6-411d-bde8-0de1b8336ddb",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "Missing values are data points where no data value is stored for the variable in an observation. They can occur for various reasons, such as data entry errors, data corruption, or simply because the data was not collected.\n",
    "\n",
    "Importance of handling missing values:\n",
    "\n",
    "Data Integrity: Missing values can lead to incorrect or biased analysis if not handled properly.\n",
    "Algorithm Performance: Many machine learning algorithms do not support missing values and will fail if they encounter them.\n",
    "Model Accuracy: Proper handling of missing values can improve the accuracy and robustness of predictive models.\n",
    "Algorithms not affected by missing values:\n",
    "\n",
    "Decision Trees: They can handle missing values by finding the best split even when some data is missing.\n",
    "Random Forests: They use decision trees as base learners, so they can also handle missing values.\n",
    "K-Nearest Neighbors (KNN): Can impute missing values based on the nearest neighbors' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f882f-58df-4e73-97fd-0579a6b0f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with Python code.\n",
    "Techniques to handle missing data:\n",
    "\n",
    "Deletion Methods:\n",
    "\n",
    "Listwise Deletion: Remove all rows with any missing values.\n",
    "Pairwise Deletion: Use all available data to calculate each statistic, handling missing data on a case-by-case basis.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4], 'B': [5, None, 7, 8]})\n",
    "df_listwise = df.dropna()  # Listwise deletion\n",
    "df_pairwise = df.dropna(how='all')  # Pairwise deletion\n",
    "\n",
    "Imputation Methods:\n",
    "\n",
    "Mean/Median Imputation: Replace missing values with the mean or median of the column.\n",
    "Mode Imputation: Replace missing values with the mode (most frequent value) of the column.\n",
    "K-Nearest Neighbors (KNN) Imputation: Use the values of the nearest neighbors to impute missing values.\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_mean_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d5369-9c74-40e1-94ea-986416a1806a",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "Imbalanced data occurs when the classes in a dataset are not represented equally. This is common in scenarios such as fraud detection, rare disease prediction, and anomaly detection.\n",
    "\n",
    "Consequences of not handling imbalanced data:\n",
    "\n",
    "Model Bias: The model may become biased towards the majority class, leading to poor performance in predicting the minority class.\n",
    "Poor Metric Scores: Standard evaluation metrics like accuracy can be misleading, as they may show high accuracy by predicting the majority class correctly while failing on the minority class.\n",
    "Inaccurate Predictions: Important minority class instances may be misclassified, leading to critical decision-making errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b924ae-9a71-42d0-8a79-389769388038",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
    "Up-sampling (or oversampling) involves increasing the number of instances in the minority class by replicating them or generating synthetic data.\n",
    "\n",
    "Down-sampling (or undersampling) involves decreasing the number of instances in the majority class by randomly removing them.\n",
    "\n",
    "When required:\n",
    "\n",
    "Up-sampling: Used when you have enough computing resources and want to balance the dataset without losing any information from the majority class.\n",
    "Down-sampling: Used when the majority class is very large, and you want to reduce computational load and make the classes balanced.\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Up-sampling\n",
    "minority_class = df[df['class'] == 1]\n",
    "majority_class = df[df['class'] == 0]\n",
    "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
    "df_upsampled = pd.concat([majority_class, minority_upsampled])\n",
    "\n",
    "# Down-sampling\n",
    "majority_downsampled = resample(majority_class, replace=False, n_samples=len(minority_class), random_state=42)\n",
    "df_downsampled = pd.concat([majority_downsampled, minority_class])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f127c1-79de-4608-8a71-940e93865510",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE.\n",
    "Data Augmentation involves creating additional training data by applying transformations such as rotation, scaling, cropping, and flipping to existing data. This is commonly used in image processing.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) generates synthetic samples for the minority class by interpolating between existing minority class instances. This helps balance the dataset and improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58267449-b4c2-4762-a378-f61715c9e1b8",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "Outliers are data points that are significantly different from the majority of the data. They can be caused by variability in the data or errors in data collection.\n",
    "\n",
    "Importance of handling outliers:\n",
    "\n",
    "Impact on Analysis: Outliers can skew the results of statistical analyses, leading to incorrect conclusions.\n",
    "Model Performance: Outliers can negatively affect the performance of machine learning models, especially those sensitive to data distribution like linear regression.\n",
    "Data Integrity: Handling outliers ensures the dataset accurately represents the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4995b-6f1a-4601-b7e2-2543c7b8fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: Techniques to handle missing data in customer analysis.\n",
    "Deletion: Remove rows with missing values if the missingness is random and the proportion is small.\n",
    "Imputation: Use techniques like mean, median, mode, or more advanced methods like KNN or multiple imputation to fill in missing values.\n",
    "Predictive Modeling: Use machine learning models to predict and fill in missing values based on other available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50bd52-c1eb-4f90-a254-6afb5d036014",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: Strategies to determine if missing data is random or patterned.\n",
    "Missing Completely at Random (MCAR): Check if the missingness is independent of both observed and unobserved data.\n",
    "Missing at Random (MAR): Check if the missingness is related to observed data but not the missing data itself.\n",
    "Missing Not at Random (MNAR): Check if the missingness is related to the missing data itself.\n",
    "Example:\n",
    "    import missingno as msno\n",
    "msno.matrix(df)\n",
    "msno.heatmap(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4019be6-f6c6-450b-b4de-5184de3fe888",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Strategies for evaluating the performance of models on imbalanced datasets.\n",
    "Use appropriate evaluation metrics: Precision, recall, F1-score, ROC-AUC, etc.\n",
    "Resampling techniques: Up-sampling, down-sampling, or SMOTE.\n",
    "Ensemble methods: Use methods like bagging, boosting, and stacking to improve model performance.\n",
    "Cost-sensitive learning: Assign different misclassification costs to handle the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43d81d-6616-4cfc-aa3f-7899f2cad743",
   "metadata": {},
   "outputs": [],
   "source": [
    "10: Methods to balance datasets with down-sampling.\n",
    "Random Under-sampling: Randomly remove instances from the majority class to balance the dataset.\n",
    "Cluster-based Under-sampling: Use clustering algorithms to identify and remove redundant data points from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031ffc0-2385-438b-a853-516542eef0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11: Methods to balance datasets with up-sampling.\n",
    "Random Over-sampling: Randomly replicate instances of the minority class to balance the dataset.\n",
    "SMOTE: Generate synthetic samples for the minority class.\n",
    "ADASYN: Similar to SMOTE but generates more synthetic samples for harder-to-learn instances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
