{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80371d9f-7ff2-4d37-ad19-ab89e9b31e6d",
   "metadata": {},
   "source": [
    "1. What is Elastic Net Regression and how does it differ from other regression techniques?\n",
    "Elastic Net Regression:\n",
    "\n",
    "Definition: Elastic Net Regression is a regularized regression technique that combines the penalties of Lasso (L1) and Ridge (L2) methods. The objective function is:\n",
    "Loss\n",
    "=\n",
    "RSS\n",
    "+\n",
    "ùõº\n",
    "(\n",
    "ùúÜ\n",
    "1\n",
    "‚àë\n",
    "ùëó\n",
    "=\n",
    "1\n",
    "ùëù\n",
    "‚à£\n",
    "ùõΩ\n",
    "ùëó\n",
    "‚à£\n",
    "+\n",
    "ùúÜ\n",
    "2\n",
    "‚àë\n",
    "ùëó\n",
    "=\n",
    "1\n",
    "ùëù\n",
    "ùõΩ\n",
    "ùëó\n",
    "2\n",
    ")\n",
    "Loss=RSS+Œ±(Œª \n",
    "1\n",
    "‚Äã\n",
    "  \n",
    "j=1\n",
    "‚àë\n",
    "p\n",
    "‚Äã\n",
    " ‚à£Œ≤ \n",
    "j\n",
    "‚Äã\n",
    " ‚à£+Œª \n",
    "2\n",
    "‚Äã\n",
    "  \n",
    "j=1\n",
    "‚àë\n",
    "p\n",
    "‚Äã\n",
    " Œ≤ \n",
    "j\n",
    "2\n",
    "‚Äã\n",
    " )\n",
    "\n",
    "where \n",
    "ùúÜ\n",
    "1\n",
    "Œª \n",
    "1\n",
    "‚Äã\n",
    "  and \n",
    "ùúÜ\n",
    "2\n",
    "Œª \n",
    "2\n",
    "‚Äã\n",
    "  are the mixing parameters that control the contribution of the L1 and L2 penalties.\n",
    "Difference:\n",
    "Ordinary Least Squares (OLS) Regression: No regularization, leading to potential overfitting if there are many predictors or multicollinearity.\n",
    "Ridge Regression: Adds L2 penalty (sum of squares of coefficients), which shrinks coefficients but does not set any to zero.\n",
    "Lasso Regression: Adds L1 penalty (sum of absolute values of coefficients), which can shrink some coefficients to zero, performing feature selection.\n",
    "Elastic Net: Combines both L1 and L2 penalties, offering a balance between Ridge and Lasso. It can select groups of correlated features and is robust to multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dbc4bf-a408-4009-9edb-5a9e27c1da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n",
    "Choosing Optimal Values:\n",
    "\n",
    "Cross-Validation: Use cross-validation to select the optimal values for \n",
    "ùúÜ\n",
    "1\n",
    "Œª \n",
    "1\n",
    "‚Äã\n",
    "  (L1 penalty) and \n",
    "ùúÜ\n",
    "2\n",
    "Œª \n",
    "2\n",
    "‚Äã\n",
    "  (L2 penalty). This is typically done using a grid search over a range of values for \n",
    "ùõº\n",
    "Œ± and \n",
    "ùúÜ\n",
    "Œª.\n",
    "Example with Python:\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Example data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [1, 2, 3, 4]\n",
    "\n",
    "# ElasticNetCV automatically selects the best alpha and l1_ratio\n",
    "model = ElasticNetCV(cv=5)\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f\"Optimal alpha: {model.alpha_}\")\n",
    "print(f\"Optimal l1_ratio: {model.l1_ratio_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7a54d-4277-4622-8f83-fa717cd292b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What are the advantages and disadvantages of Elastic Net Regression?\n",
    "Advantages:\n",
    "\n",
    "Feature Selection: Combines the strengths of Lasso in feature selection and Ridge in handling multicollinearity.\n",
    "Flexibility: Can select a mixture of L1 and L2 regularization, providing more flexibility.\n",
    "Robustness: Better handles situations with highly correlated predictors.\n",
    "Disadvantages:\n",
    "\n",
    "Complexity: More complex than Ridge or Lasso due to the need to tune two hyperparameters (\n",
    "ùõº\n",
    "Œ± and \n",
    "ùúÜ\n",
    "Œª).\n",
    "Interpretability: Can be less interpretable than simpler models due to the combination of penalties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24b635-381c-46e3-bd9b-8855df43bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are some common use cases for Elastic Net Regression?\n",
    "Use Cases:\n",
    "\n",
    "High-Dimensional Data: When the number of predictors exceeds the number of observations.\n",
    "Multicollinearity: When predictors are highly correlated.\n",
    "Feature Selection: When it's important to identify the most relevant features.\n",
    "Genomics: Used in fields like genomics where there are many predictors and correlations among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17b690-c33c-4bc7-af4a-ff111c6e802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How do you interpret the coefficients in Elastic Net Regression?\n",
    "Interpreting Coefficients:\n",
    "\n",
    "Magnitude: The size of the coefficient indicates the strength of the relationship between the predictor and the response variable.\n",
    "Sign: The sign of the coefficient indicates the direction of the relationship.\n",
    "Zero Coefficients: Coefficients that are exactly zero indicate features that are not selected by the model (similar to Lasso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb8004-0939-462d-b4e7-a3eb783231fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How do you handle missing values when using Elastic Net Regression?\n",
    "Handling Missing Values:\n",
    "\n",
    "Imputation: Common strategies include mean, median, or mode imputation for missing values.\n",
    "Advanced Imputation: Use more sophisticated methods like K-Nearest Neighbors (KNN) imputation or regression imputation.\n",
    "Example:\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Example data with missing values\n",
    "X = [[1, 2], [3, None], [5, 6], [7, 8]]\n",
    "y = [1, 2, 3, 4]\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Fit Elastic Net model\n",
    "model = ElasticNet()\n",
    "model.fit(X_imputed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d89017-f097-4abf-8817-4cc40474cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How do you use Elastic Net Regression for feature selection?\n",
    "Feature Selection:\n",
    "\n",
    "Process: Elastic Net can shrink some coefficients to zero, effectively removing irrelevant features.\n",
    "Implementation: Fit the Elastic Net model and examine which coefficients are non-zero.\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Example data\n",
    "X = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "y = [1, 2, 3, 4]\n",
    "\n",
    "# Fit Elastic Net model\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Check non-zero coefficients\n",
    "print(f\"Non-zero coefficients: {model.coef_ != 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d4961-92d0-4e2a-87bb-f05c1b9ac4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?\n",
    "Pickling and Unpickling:\n",
    "\n",
    "Pickling: Serialize the trained model to a file.\n",
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Example data\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [1, 2, 3, 4]\n",
    "\n",
    "# Fit Elastic Net model\n",
    "model = ElasticNet()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Pickle the model\n",
    "with open('elastic_net_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "Unpickling: Deserialize the model from the file.\n",
    "# Unpickle the model\n",
    "with open('elastic_net_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "predictions = loaded_model.predict([[1, 2], [3, 4]])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7b285-aafc-4b61-b7f3-d159f06b9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. What is the purpose of pickling a model in machine learning?\n",
    "Purpose of Pickling:\n",
    "\n",
    "Model Persistence: Save trained models to disk so they can be loaded and used later without retraining.\n",
    "Reusability: Facilitate the reuse of models in different environments or applications.\n",
    "Deployment: Make it easier to deploy models in production settings, where retraining every time is impractical.\n",
    "Efficiency: Save time and computational resources by avoiding the need to retrain models repeatedly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
